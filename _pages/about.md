---
permalink: /
title: "ğŸ‘‹ Hello there, I am Haocan!"
excerpt: ""
author_profile: true
redirect_from: Â Â Â Â Â Â 
  - /about/Â Â 
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am a third-year master's student at the Cognitive Neuroscience Communication Lab at Beijing Normal University, supervised by Professor Guoming Yu. My primary research focuses on human-computer interaction and cognitive neuroscience communication. Since 2019, I have also collaborated with Professor Kun Tang at Tsinghua University on projects related to adolescent health and well-being, as well as sexual and reproductive health and rights (SRHR). In the lab, I am mainly responsible for data analysis and have independently led multiple projects. In 2022, I earned my degree in Arts from the Communication University of China in TV Editing and Directing.

My academic background lies at the intersection of communication studies, public health, psychology, and cognitive neuroscience. I believe that as mediaâ€”especially AIâ€”becomes deeply interwoven with our lives, there is a pressing need for scholars with interdisciplinary expertise to seize opportunities for groundbreaking innovation. Therefore, I am dedicated to using cross-disciplinary approaches to address real-world health issues, regardless of traditional academic boundaries. I have published 3 papers, with 3 others currently under review.  <a href='https://scholar.google.com/citations?user=tr33OgQAAAAJ&hl=zh-CN&oi=ao'><img src="https://img.shields.io/badge/Citations-9cf?style=flat&logo=Google%20Scholar">
</a>


# ğŸ“ Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2016</div><img src='images/pornography paper.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Deep Residual Learning for Image Recognition](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)

**Kaiming He**, Xiangyu Zhang, Shaoqing Ren, Jian Sun

[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>

- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**

# ğŸ– Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# ğŸ“– Educations
- *2019.06 - 2022.04 (now)*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2015.09 - 2019.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# ğŸ’¬ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# ğŸ’» Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.
